{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Time series analysis with ARIMA\n",
    "We are going to predict the number of internation airline passengers using ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Defaults\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ts = pd.read_csv('international-airline-passengers.csv', engine='python', skipfooter=3)\n",
    "ts['Month']=pd.to_datetime(ts['Month'], format='%Y-%m-%d')\n",
    "ts.set_index(['Month'], inplace=True)\n",
    "\n",
    "# Plot the data\n",
    "ts.plot()\n",
    "plt.ylabel('Monthly airline passengers (x1000)')\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity is defined using a very strict criterion. However, for practical purposes we can assume the series to be stationary if it has constant statistical properties over time, ie. the following:\n",
    "\n",
    "* Constant mean\n",
    "* Constant variance\n",
    "* An autocovariance that does not depend on time.\n",
    "\n",
    "<b>Plotting Rolling Statistics:</b> We can plot the moving average or moving variance and see if it varies with time. By moving average/variance I mean that at any instant ‘t’, we’ll take the average/variance of the last year, i.e. last 12 months. But again this is more of a visual technique.\n",
    "\n",
    "<b>Dickey-Fuller Test:</b> This is one of the statistical tests for checking stationarity. Here the null hypothesis is that the TS is non-stationary. The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. If the ```Test Statistic``` is less than the ```Critical Value```, we can reject the null hypothesis and say that the series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    # Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window=12).mean()\n",
    "    rolstd = timeseries.rolling(window=12).std()\n",
    "\n",
    "    # Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    ### IMPLEMENT AUGMENTED DICKEY-FULLER TEST\n",
    "    ### BE CAREFUL WITH THE EXPECTED INPUT DIMENSION OF ADFULLER\n",
    "    ### WE ARE USING A 1 DIMENSIONAL TIME SERIES\n",
    "    # dftest = .....\n",
    "\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    print(dfoutput)\n",
    "\n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its obviously not stationary at the moment. Lets understand what is making a TS non-stationary. There are 2 major reasons behind non-stationarity of a TS:\n",
    "1. **Trend** – varying mean over time. For eg, in this case we saw that on average, the number of passengers was growing over time.\n",
    "2. **Seasonality** – variations at specific time-frames. eg people might have a tendency to buy cars in a particular month because of pay increment or festivals.\n",
    "\n",
    "The underlying principle is to model or estimate the trend and seasonality in the series and remove those from the series to get a stationary series. Then statistical forecasting techniques can be implemented on this series. The final step would be to convert the forecasted values into the original scale by applying trend and seasonality constraints back.\n",
    "\n",
    "\n",
    "## Eliminating trend \n",
    "\n",
    "To eliminate **trend** we will apply a transformation that makes the values more or less same, ie. we use log\n",
    "\n",
    "One simple way that could eliminate trend is to apply a log transformation to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT LOG TRANSFORMATION AND PLOT THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's already slightly better but we still have to account for the noise, for this we can use a rolling average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT ROLLING AVERAGE WITH PANDAS AND PLOT BOTH THE ORIGINAL (LOG) DATA AND THE AVERAGED DATA\n",
    "### THINK ABOUT A PROPER WINDOW SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is obviously still a strong trend observable but note that we can make the series stationary now by subtracting the rolling average from the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUBTRACT THE MEAN TO MAKE THE SYSTEM STATIONARY AND TEST BOTH FOR STATIONARITY\n",
    "### THINK ABOUT HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila, our time series are now stationary with a confidence level of > 97.5 percent ! \n",
    "\n",
    "Furthermore, since it can be hard to estimate a good rolling window, we took 12 now because of the monthly dependence we can also use an exponential weighted average that is less parameter dependent (you can set halflife=12):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATE EXPONENTIONAL WEIGHTED MOVING AVERAGE, AGAIN USE PANDAS\n",
    "### AGAIN SUBTRACT THE WEIGHTED AVERAGE FROM THE LOG SERIES\n",
    "### PLOT AND TEST FOR STATIONARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test statistic is now lower than 1% critical value, it means that we are 99% sure that we have a stationary series.\n",
    "\n",
    "\n",
    "## Differencing ##\n",
    "Another good way to eliminate trend and seasonality is by differencing the input, remember the differencing part of the ARIMA model:\n",
    "\n",
    "$X'_t = X_t - X_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT 1D DIFFERENCING HERE AND TEST STATIONARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mm, reasonable results but we could do slightly better, let's try differencing twice over the input:\n",
    "\n",
    "$X'_t = (X_t - X_{t-1}) - (X_{t-1} - X_{t-2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT TWO TIMES DIFFERENCING AND TEST FOR STATIONARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty huh! This is exactly what the ARIMA model does when d=2, the idea is to remove the non stationarity before fitting a linear model, after which we can add this back to our fitted model when doing predictions.\n",
    "\n",
    "## Decomposition ##\n",
    "\n",
    "Next up, we can decompose the time series in a series of factors to extract the characteristics (trend, seasonality and residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "### IMPLEMENT DECOMPOSITION AND USE PLOT FUNCTION\n",
    "\n",
    "def plot_decomposition(log_original, trend, seasonality, residuals):\n",
    "    plt.subplot(411)\n",
    "    plt.plot(log_original, label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(trend, label='Trend')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(seasonality,label='Seasonality')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(residuals, label='Residuals')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHOW THAT THE RESIDUALS FROM THIS METHOD ARE STATIONARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "ARIMA stands for Auto-Regressive Integrated Moving Average. There are three  integers (p, d, q) that are used to parametrize ARIMA models. Because of that, a nonseasonal ARIMA model is denoted with ARIMA(p, d, q): \n",
    "<ul>\n",
    "<li><strong>p</strong> is the number of autoregressive terms (AR part). It allows to incorporate the effect of past values into our model. Intuitively, this would be similar to stating that it is likely to be warm tomorrow if it has been warm the past 3 days.</li>\n",
    "<li><strong>d</strong> is the number of nonseasonal differences needed for stationarity. Intuitively, this would be similar to stating that it is likely to be same temperature tomorrow if the difference in temperature in the last three days has been very small.</li>\n",
    "<li><strong>q</strong> is the number of lagged forecast errors in the prediction equation (MA part). This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past.</li>\n",
    "</ul>\n",
    "\n",
    "When dealing with seasonal effects, as in our example, seasonal ARIMA is used, which is denoted as ARIMA(p,d,q)(P,D,Q)s. Here, (p, d, q) are the nonseasonal parameters described above, (<strong>P, D, Q</strong>) follow the same definition but are applied to the seasonal component of the time series. The term <strong>s</strong> is the periodicity of the time series.\n",
    "\n",
    "While in this case it is clear that s=12, how do we set the other parameters? \n",
    "\n",
    "It is pretty much based on experience. There are numerous best practices that can be followed to identify ARIMA models, such as: \n",
    "http://people.duke.edu/~rnau/arimrule.htm.\n",
    "\n",
    "For ease we now use a grid search over all possible combinations of parameter values within a predefined range of values. \n",
    "\n",
    "$statsmodels.tsa.statespace.sarimax.SARIMAXResults$ returns values for AIC (Akaike Information Criterion) and BIC (Bayes Information Criterion) that can be minimized to select the best fitting model. We use the AIC value, which estimates the information lost when a given model is used to represent the process that generates the data. In doing so, it deals with the trade-off between the goodness of fit of the model and the complexity of the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter range and get cross product\n",
    "q = d = range(0, 2)\n",
    "p = range(0, 4)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a subset of the data series as training data, say the first 11 years. Our goal is to predict the last year of the series based on this input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ts['1949-01-01':'1959-12-01']\n",
    "test_data = ts['1960-01-01':'1960-12-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to fit the model, we will use the SARIMAX model from the statsmodel package:\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        ### FIT THE BEST POSSIBLE MODEL USING A GRID SEARCH BASED ON THE LOWEST AIC VALUE\n",
    "        ### WE NEED THE BEST SETTING LATER ON FOR PREDICTION!\n",
    "        ### BE SURE TO SET enforce_stationarity AND enforce_invertibility to false\n",
    "        \n",
    "        # model = ....\n",
    "\n",
    "        results = model.fit()\n",
    "\n",
    "        print('SARIMAX{}x{} - AIC:{}'.format(param, param_seasonal, results.aic), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIT THE BEST POSSIBLE MODEL\n",
    "\n",
    "results = mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n",
    "Now let's create some predictions. We can use the get_prediction() function of the model:\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.get_prediction.html\n",
    "\n",
    "We will use three methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) In sample prediction with 1-step ahead forecasting of the last year (1959). In this case the model is used to predict data that the model was built on. 1-step ahead forecasting implies that each forecasted point is used to predict the following one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT IN-SAMPLE PREDICTION WITHOUT DYNAMIC FORECASTING (START 1958-01-01)\n",
    "# pred0 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) In sample prediction with dynamic forecasting of the last year (1959). Again, the model is used to predict data that the model was built on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT IN-SAMPLE PREDICTION WITH DYNAMIC FORECASTING (START 1958-01-01)\n",
    "# pred1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) \"True\" forecasting of out of sample data. In this case the model is asked to predict data it has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT OUT-OF-SAMPLE FORECASTING (END 1962-12-01) (check get_forecast()) \n",
    "# pred2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For out of sample predictions it can be useful to get the confidence interval, such that we have a measure of how sure the model is about a certain prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPLEMENT CONFIDENCE INTERVAL ON GENERATED PREDICTIONS\n",
    "# pred2_ci = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ts.plot(figsize=(20, 16))\n",
    "pred0.predicted_mean.plot(ax=ax, label='1-step-ahead Forecast (get_predictions, dynamic=False)')\n",
    "pred1.predicted_mean.plot(ax=ax, label='Dynamic Forecast (get_predictions, dynamic=True)')\n",
    "pred2.predicted_mean.plot(ax=ax, label='Dynamic Forecast (get_forecast)')\n",
    "ax.fill_between(pred2_ci.index, pred2_ci.iloc[:, 0], pred2_ci.iloc[:, 1], color='k', alpha=.1)\n",
    "plt.ylabel('Monthly airline passengers (x1000)')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the figure, the model seems to do a pretty good job at modeling the time series. The blue and purple lines are, as expected, very close to the red ground truth. What is more interesting is the gray line, the out of sample prediction. For such a simple time series, the ARIMA model is able to forecast the 1960 values fairly accurately. What else is catching your attention?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
